import os
import streamlit as st
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.vectorstores import FAISS
import tempfile
from langchain.document_loaders import PyPDFLoader

os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
uploaded_file = st.sidebar.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")

system_message = '''
ë„ˆëŠ” ë°°ë ¤ ë„˜ì¹˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ ì±—ë´‡ì´ì•¼.
í•­ìƒ ì¹œê·¼í•˜ê²Œ ëŒ€ë‹µí•´ì¤˜. ì˜ì–´ë¡œ ì§ˆë¬¸í•´ë„ ë¬´ì¡°ê±´ í•œê¸€ë¡œ ë‹µë³€í•´ì¤˜.
ë‹µë³€í•  ë•Œ ì—…ë¡œë“œëœ PDF íŒŒì¼ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ê´€ë ¨ëœ ì •ë³´ë¥¼ ì œê³µí•´ì¤˜. 
ì§§ê²Œ ë¬¼ì–´ë³´ë”ë¼ë„ ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì´ê³  ìì„¸í•˜ê²Œ ì„¤ëª…í•´ ì£¼ê³ , ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë  ë§Œí•œ ì¶”ê°€ ì •ë³´ë„ ì œê³µí•´ì¤˜.
'''

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": system_message}]
    st.session_state.history = []

if uploaded_file:
    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name

    loader = PyPDFLoader(tmp_file_path)
    data = loader.load()

    embeddings = OpenAIEmbeddings()
    vectors = FAISS.from_documents(data, embeddings)

    chain = ConversationalRetrievalChain.from_llm(llm=ChatOpenAI(temperature=0.0, model_name='gpt-4o'), retriever=vectors.as_retriever())

    def conversational_chat(query):
        # "Running..." ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.markdown("ë‹µë³€ì„ ì¤€ë¹„ì¤‘ì´ì—ìš”..! ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”. ğŸ˜Š")  # ì‚¬ìš©ìì—ê²Œ ë¡œë”© ì¤‘ì„ì„ ì•Œë¦¼

            # ConversationalRetrievalChainì„ í†µí•´ ë‹µë³€ì„ ê°€ì ¸ì˜¤ê¸°
            result = chain({"question": query, "chat_history": st.session_state.history})
            message_placeholder.markdown(result["answer"] + " ğŸ˜Š")

        st.session_state.history.append((query, result["answer"]))
        return result["answer"]

    st.title("ChatGPT í˜•íƒœì˜ ì±—ë´‡")

    # ì±„íŒ… ë©”ì‹œì§€ ì¶œë ¥
    for message in st.session_state.messages:
        if message["role"] != "system":
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # ì±„íŒ… ì…ë ¥
    if prompt := st.chat_input("PDF ë‚´ìš©ì„ ì§ˆë¬¸í•´ë³´ì„¸ìš”!"):
        user_message = {"role": "user", "content": prompt}
        st.session_state.messages.append(user_message)

        with st.chat_message("user"):
            st.markdown(prompt)

        assistant_message_content = conversational_chat(prompt)
        assistant_message = {"role": "assistant", "content": assistant_message_content}

        st.session_state.messages.append(assistant_message)
else:
    st.warning("ğŸ“‚ PDF íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”!")